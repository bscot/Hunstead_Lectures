{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa672a4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Contemporary Machine Learning\n",
    "\n",
    "##  2024 University of Sydney Hunstead Lecture 3\n",
    "### Bryan Scott, CIERA | Northwestern University\n",
    "\n",
    "Based on a lecture from LSST DA Data Science Fellowship Program Session 19: Machine Learning held at Drexel University in Philadelphia, Pennsylvania, United States\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e07a21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goals for the Lecture\n",
    "\n",
    "The goal for this talk is to provide some background for contemporary Machine Learning, and to (start to) answer the following questions:\n",
    "\n",
    "- What is Machine Learning? How is different from statistics?\n",
    "- Where did the field come from? Where is it going?\n",
    "- When do we use Machine Learning and what are its limitations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcddd62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further Resources\n",
    "\n",
    "Machine Learning is an extremely active field. Some books that you might look at with increasing levels of sophistication:\n",
    "\n",
    "- $\\textit{Introduction to Machine Learning with Python}$, by Muller & Guido\n",
    "- $\\textit{Statistics, Data Mining, and Machine Learning in Astronomy}$, by IveziÄ‡, Connolly, VanderPlas, and Gray: Documentation and software is available here: https://www.astroml.org\n",
    "- $\\textit{Machine Learning for Physics and Astronomy}$, by Acquaviva \n",
    "- $\\textit{Introduction to Statistical Learning}$, by James, Witten, Hastie & Tibshirani - available from the atuhors here: https://www.statlearning.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9378a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe760e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Early ML Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73525b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### When do you want to use Machine Learning?\n",
    "\n",
    "$\\textit{Discuss with those around you.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491f893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When do we need machine learning? \n",
    "\n",
    "First, when a task is to complex to perform. That is, where it is\n",
    "- hard to specify an algorithm for solving the problem\n",
    "- the data is very large or complex\n",
    "\n",
    "Second, tasks that require adaptivity\n",
    "- where a task must change as a result of interaction with the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab49287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The (Formal) Structure of the Learning Problem\n",
    "\n",
    "A Learning Problem consists of the following parts\n",
    "\n",
    "$\\mathit{X}$ - a domain set or instance space of examples. These are usually n-dimensional vectors. We call the components of these vectors, $\\textit{features}$.\n",
    "\n",
    "$\\mathit{Y}$ - the label set, in supervised learning problems these are the set of possible $\\textit{labels}$ for each element in $\\mathit{X}$.\n",
    "\n",
    "$\\mathit{S}$ - the training set. These are ordered pairs of elements from $\\mathit{X}$ and $\\mathit{Y}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e588b50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For many problems, we additionally assume there is some true mapping $f: \\mathit{X} \\rightarrow \\mathit{Y}$. These problems are called $\\textit{supervised learning}$. If a true mapping does not exist, we call this an $\\textit{unsupervised learning}$ problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf28ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formally, the (supervised) learning problem is to learn, estimate, or approximate the true map $\\mathit{f}$ from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16517144",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We therefore distinguish between f and the output of the learner h, which is (at best) an approximation of f. \n",
    "\n",
    "$\\mathit{h}$ - the output of some learning algorithm. This is a prediction rule that tells us Y given some X. $\\mathit{h}: \\mathit{X} \\rightarrow  \\mathit{Y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1091e5c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside: Universal Approximation Theorems \n",
    "\n",
    "\"In the mathematical theory of artificial neural networks, universal approximation theorems are theorems of the following form: Given a family of neural networks, for each function \n",
    "f from a certain function space, there exists a sequence of neural networks $\\phi_1, \\phi_2,...$ such that $\\phi_N \\rightarrow f$ according to some criterion.\" [Wikipedia]\n",
    "\n",
    "Intuitively: Neural Networks (generalized perceptrons) can approximate a broad class of functions. How do we pick such an approximation? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d96e14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss Functions\n",
    "\n",
    "To enable learning, we will need a function, called a $\\textit{loss function}$, that tells us how wrong we are. Big values of the loss mean we're very wrong while small values mean we're less wrong. \n",
    "\n",
    "A common loss function is the mean squared error: \n",
    "\n",
    "$$\n",
    "L_S(h) = \\frac{1}{m} \\Sigma |h(x) - y(x)|^2\n",
    "$$\n",
    "\n",
    "for an estimator h, and features x for m training points $\\in$ S. Other loss functions exist, such as the $\\textit{absolute error}$ (rather than mean squared error), $\\textit{0-1 loss}$ (0 if the prediction of h is false, 1 if true; for binary classification problems), etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22af3a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For every distribution you sample data from, is it possible to construct an algorithm such that for any dataset of size m, you can gurantee with high confidence that the loss will be small? \n",
    "\n",
    "**Discuss with those around you.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc788b31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## No Free Lunch Theorem\n",
    "\n",
    "No, this is not possible due to a result called the \"No Free Lunch Theorem\" which (intuitively) states that a learning algorithm observing a subset of the instance spaces can learn a function that fits the subset but will fail on a disjoint unobserved subset. \n",
    "\n",
    "That means there is no universal learning function that can be applied to all problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af73fa7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Optimal Decision Rules and Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e6790b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we have just seen, for real problems, we don't know the distribution the data is sampled from and this prevents us from having a 'free lunch'. Nonetheless, we can draw some important insights into selecting the learned function h by considering the expected loss (or risk) computed with respect to the true $\\textit{joint distribution}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebca7d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The expectation value of the loss, or the risk $r$, is:\n",
    "\n",
    "$$\n",
    "r(h(X)) = \\int \\int L(h(X), Y) p(X, Y) dY dX\n",
    "$$\n",
    "\n",
    "A higher value of the loss means that our learned function h(X) is doing a poor job of predicting the values of Y. We therefore want to treat this as a minimization problem for h(X). Our best choice of h(X) is the one that minimizes the risk. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36094fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Typically, we take one additional step of rewriting this in terms of the conditional distribution:  \n",
    "\n",
    "$$\n",
    "r(h(X)) = \\int \\left[\\int L(h(X), Y) p(Y|X) dY \\right] p(X) dX\n",
    "$$\n",
    "\n",
    "where the term in brackets is smallest for the \"optimal choice\" of loss function $L(h(X), Y)$. We can therefore pick the optimal h(X) for a given loss function by minimizing the term in brackets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eca74d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From yesterday's lecture, you should recognize p(Y|X) as the $\\textit{posterior}$ distribution for Y conditioned on X. Unfortunately, we don't know the posterior distribution for real problems. Nonetheless, we can, for example, make use of this approach to arrive at some useful results. One example is in the case of binary classification, we set $h(X) = argmax_a p(Y=a | X)$, in other words, the mode of the conditional posterior distribution $p(Y=a | X)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9eca07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is an example of a Bayes Classifier. The tutorial will ask you to write your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bff53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is Learning difficult?\n",
    "\n",
    "A few reasons:\n",
    "- in general, the true function $\\mathit{f}$ could be very complicated and non-linear. \n",
    "- more generally, we don't know what model generated the dataset X. We assume it is sampled from some distribution $\\mathit{X} \\sim \\mathscr{D}$, where we do not have access to $\\mathscr{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa69e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aside: Generative models attempt to learn the $\\textbf{data generating distribution}$ $\\mathscr{D}$ in order to generate new examples from it that weren't in the training set. \n",
    "\n",
    "These are very popular right now but caution is warranted - the study of generative models is still in its early stages (especially in astronomy) and there are many limitations and caveats around them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa30ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Taken together, this means we have to think carefully about our uncertainties on the outputs of learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70b261",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uncertainty in Machine Learning\n",
    "\n",
    "We can decompose the error on our estimate of the function h into two parts:\n",
    "\n",
    "- $\\epsilon_{app}$: the approximation error that arises from our learner not being 'perfect', or in other words, from the fact that $\\mathit{h} \\ne \\mathit{f}$ in general\n",
    "- $\\epsilon_{est}$: the estimation error that arises from $\\mathit{X} \\sim \\mathscr{D}$.\n",
    "\n",
    "Our estimator for our learning error is a combination of both terms. Importantly, it is estimated from the training data $S \\sim \\mathit{X} \\sim \\mathscr{D}$, which means that the error is itself a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066be4c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What can we do about our learning errors?\n",
    "\n",
    "As an example, we generally want a rich set of possible functions $\\mathit{h}$ to learn from. This decreases the $\\epsilon_{app}$ since we can pick better (less biased) $\\textit{h}$ than we could with a smaller set of functions to pick from, however $\\epsilon_{est}$ increases (the variance increases) with how complicated our set of possible $\\mathit{h}$ is.\n",
    "\n",
    "This is called the $\\textit{bias-variance tradeoff}$. In statistics, there is a formal limit on the bias and variance called the $\\textit{Cramer-Rao } bound$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60cc4cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cramer-Rao Bound: A brief interlude...\n",
    "\n",
    "Suppose you have data X sampled from some distribution $Pr(\\theta)$. If $\\theta$ is estimated by some function of the data T(X), then the variance and bias of estimates are related by\n",
    "\n",
    "$$\n",
    "Var(T(X)) \\ge \\frac{\\left(\\frac{d}{d\\theta} \\mathbb{E}\\left(T(x)\\right)\\right)^2}{\\mathbb{E} \\left(\\frac{d}{d\\theta} log f\\left(X; \\theta \\right)\\right)^2}\n",
    "$$\n",
    "\n",
    "The left side is the variance - while the right side depends on whether the estimate of $\\theta$ is biased. If it's unbiased, the expectation is $\\theta$ and the numerator is one. The denominator is a term called the Fisher information - which tells you how sensitive the likelihood function is to changes in its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecebdd8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting it all together - Probably Approximately Correct (PAC) Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ecd540",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What we've seen so far is that machine (or statistical) learning methods:\n",
    "\n",
    "- There is error due to failures of the learner, parameterized as $\\epsilon$. \n",
    "- There is error due to sampling from some unknown distribution, $S \\sim \\mathit{X} \\sim \\mathscr{D}$, parameterized as $\\delta$. \n",
    "\n",
    "This leads to a definition of the learning problem in terms of $\\textit{probably}$ ($\\delta$) $\\textit{approximately}$ ($\\epsilon$) $\\textit{correct}$ (PAC) learning. Probably captures the sampling of the data and approximately captures errors in our learning. This notion of PAC learnability allows you to make quantitative statements about, for example, how large a training set you need given how many possible functions you want to learn from the data. \n",
    "\n",
    "PAC learnability is a very common, but not the only, framework for discussing statistical/machine learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da9572",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Worry about the Data! \n",
    "\n",
    "Sophisticated techniques for reducing errors in the learner ($\\epsilon$) exist. Dealing with errors in the training sample - also called non-representativeness - are much more subtle. If our training data is biased, so will our inferences from that data! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00ae5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
